{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11714811,"sourceType":"datasetVersion","datasetId":7353383}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multi-Class Leaf Disease Detection on Vegetable Crops using CNNs and Explainable AI (XAI) with PyTorch\n\nThis dataset and analysis has been published 15 June 2024\n\nThis notebook demonstrates:\n\n1. Building a custom CNN model from scratch for multi-class leaf disease detection on six widely grown vegetable crops in Bangladesh.\n\n2. Transfer learning models (resnext101_32x8d, densenet201, efficientnetv2_m, nasnetalarge, convnext_base, and seresnext101_32x8d).\n\n3. Training with dataset augmentation and early stopping.\n\n4. Visualization of training and validation loss curves.\n\n5. Model evaluation with precision, recall, and F1-score.\n\n6. XAI techniques for best model : Grad-CAM, Grad-CAM++, Eigen-CAM, and LIME for model interpretation.","metadata":{}},{"cell_type":"markdown","source":"## Organized Plant Disease Dataset by Category and Disease Type","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nfrom pathlib import Path\n\n# Input and output directories\ninput_root_dir = \"/kaggle/input/project/project\"\noutput_root_dir = \"/kaggle/working/project\"\n\n# Image extensions\nimage_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n\ndef flatten_dataset():\n    # Clear and copy dataset\n    if os.path.exists(output_root_dir):\n        shutil.rmtree(output_root_dir)\n    shutil.copytree(input_root_dir, output_root_dir)\n\n    # Process each vegetable folder\n    for vegetable in os.listdir(output_root_dir):\n        vegetable_dir = os.path.join(output_root_dir, vegetable)\n        if not os.path.isdir(vegetable_dir):\n            continue\n\n        # Move subfolders to root level\n        for subfolder in os.listdir(vegetable_dir):\n            subfolder_path = os.path.join(vegetable_dir, subfolder)\n            if os.path.isdir(subfolder_path):\n                # For Eggplant and Tomato, move as-is\n                if vegetable in [\"Eggplant\", \"Tomato\"]:\n                    new_folder_name = subfolder\n                # For others, add vegetable name\n                else:\n                    new_folder_name = f\"{vegetable} {subfolder}\"\n                shutil.move(subfolder_path, os.path.join(output_root_dir, new_folder_name))\n        shutil.rmtree(vegetable_dir)\n\ndef count_images():\n    print(\"\\nFolder Structure and Image Counts:\")\n    print(\"-\" * 40)\n    total_images = 0\n    # Get sorted list of folders\n    folders = sorted([f for f in os.listdir(output_root_dir) if os.path.isdir(os.path.join(output_root_dir, f))])\n    \n    # Print folders with numbering\n    for idx, folder in enumerate(folders, 1):\n        folder_path = os.path.join(output_root_dir, folder)\n        image_count = sum(1 for item in os.listdir(folder_path) \n                         if os.path.isfile(os.path.join(folder_path, item)) \n                         and Path(item).suffix.lower() in image_extensions)\n        total_images += image_count\n        print(f\"{idx}. {folder}: {image_count} images\")\n    print(\"-\" * 40)\n    print(f\"Total number of images: {total_images}\")\n\ndef main():\n    flatten_dataset()\n    count_images()\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Bar Chart Representation of Folder-wise Image Counts\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\n# Output directory (where the 21 folders are located)\noutput_root_dir = \"/kaggle/working/project\"\n\n# Image extensions\nimage_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n\n# Count images and prepare data for plotting\nimage_counts = {}\nfor index, folder in enumerate(sorted(os.listdir(output_root_dir)), 1):\n    folder_path = os.path.join(output_root_dir, folder)\n    if os.path.isdir(folder_path):\n        image_count = sum(1 for item in os.listdir(folder_path) \n                         if os.path.isfile(os.path.join(folder_path, item)) \n                         and Path(item).suffix.lower() in image_extensions)\n        image_counts[f\"{index}. {folder}\"] = image_count\n\n# Create bar chart\nplt.figure(figsize=(8, 6))\nplt.bar(image_counts.keys(), image_counts.values(), color='purple')\nplt.title(\"Image Count per Category\")\nplt.xlabel(\"Category\")\nplt.ylabel(\"Number of Images\")\nplt.xticks(rotation=90)  # Changed rotation to 90 for vertical labels\nplt.tight_layout()\n\n# Save the plot\nplt.savefig(\"image_count_plot.png\")\nprint(\"\\nBar chart saved as 'image_count_plot.png'\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## A Glimpse from Every Category","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Output directory (where the 21 folders are located)\noutput_root_dir = \"/kaggle/working/project\"\n\n# Image extensions\nimage_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n\n# Display one image from each category\nplt.figure(figsize=(15, 30))  # Adjusted for 21 images\nfor index, folder in enumerate(sorted(os.listdir(output_root_dir)), 1):\n    folder_path = os.path.join(output_root_dir, folder)\n    if os.path.isdir(folder_path):\n        # Find the first image in the folder\n        for file in os.listdir(folder_path):\n            if os.path.isfile(os.path.join(folder_path, file)) and Path(file).suffix.lower() in image_extensions:\n                img_path = os.path.join(folder_path, file)\n                plt.subplot(7, 3, index)  # 7 rows, 3 columns for 21 images\n                img = mpimg.imread(img_path)\n                plt.imshow(img)\n                plt.title(f\"{index}. {folder}\")\n                plt.axis('off')\n                break  # Move to next folder after finding one image\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ## Import Required Libraries","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/jacobgil/pytorch-grad-cam.git\n\n\n!pip install lime","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom torchvision.transforms import ToTensor\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom pytorch_grad_cam import GradCAM, GradCAMPlusPlus, EigenCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom lime import lime_image\nimport zipfile\nimport os\nfrom tqdm import tqdm  # Import tqdm for progress bars","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pre-Processing and Load the Dataset\nThe original dataset contained 6 main folders, each representing a vegetable, with multiple subfolders inside corresponding to different leaf diseases and healthy leaves. To simplify training and improve clarity, we reorganized the dataset by merging all subfolders into a total of 21 separate folders—each folder now represents one specific disease class or healthy class across all vegetables. This structured organization facilitates easier loading and processing of data for training, validation, and testing phases.\n\n","metadata":{}},{"cell_type":"code","source":"# Define transformations with potential augmentations\ntransform_train = transforms.Compose([\n    transforms.RandomResizedCrop(224),      \n    transforms.RandomHorizontalFlip(),     \n    transforms.ToTensor(),                  \n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),         \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n# Load dataset\ndataset = datasets.ImageFolder(root=\"/kaggle/working/project\", transform=transform_train)\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.2 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n# Apply test transformation to validation and test sets\n\nval_dataset.dataset.transform = transform_test\ntest_dataset.dataset.transform = transform_test\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom CNN model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CustomCNN(nn.Module):\n    def __init__(self):\n        super(CustomCNN, self).__init__()\n        \n        # Convolutional Layers\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n        \n        # Fully Connected Layers\n        self.fc1 = nn.Linear(256 * 14 * 14, 512)  \n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 128)\n        self.fc4 = nn.Linear(128, 21)  # Change 3 → my number of classes\n        \n        # Dropout\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n\n        x = F.relu(self.conv4(x))\n        x = F.max_pool2d(x, 2)\n\n        x = torch.flatten(x, start_dim=1)  # Dynamic flattening\n\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n        x = self.fc4(x)\n\n   \n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Early Stopping Logic","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n\n    def __init__(self, patience=5):\n\n        self.patience = patience\n        self.counter = 0\n        self.best_loss = np.inf\n\n    def check_early_stop(self, val_loss):\n        if val_loss < self.best_loss:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train the Model and Plot Loss Curves for Custom CNN\n\n### Using AMP with Custom Model\n\nTo improve training speed, we can utilize Automatic Mixed Precision (AMP) provided by torch.cuda.amp. AMP enables faster training by using lower precision (float16) for parts of the computation while maintaining accuracy with some operations in higher precision (float32).","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm  # Import tqdm for progress bars\nfrom torch.cuda.amp import autocast, GradScaler  # Import AMP utilities\n\n# Set number of epochs and initialize variables\n\nnum_epochs = 50  # Define the number of training epochs\n\nmodel = CustomCNN().to('cuda')  # Move model to GPU\n\ncriterion = nn.CrossEntropyLoss()  # Loss function\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer with learning rate\n\nearly_stopping = EarlyStopping(patience=5)  # Initialize early stopping with patience\n\ntrain_losses, val_losses = [], []  # Lists to store training and validation losses per epoch\n\n# Initialize GradScaler for AMP\nscaler = GradScaler()\n# Loop over epochs\nfor epoch in range(num_epochs):\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    # Training phase\n    model.train()  # Set model to training mode\n    train_loss = 0  # Initialize cumulative training loss for the epoch\n    # Loop over training data with tqdm progress bar\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n        optimizer.zero_grad()  # Clear previous gradients\n        with autocast():  # Use AMP for mixed-precision calculations\n            outputs = model(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n\n        # Scale loss to avoid underflow for float16\n        scaler.scale(loss).backward()  # Backward pass with scaled loss\n        scaler.step(optimizer)  # Optimizer step\n        scaler.update()  # Update the scaler for next iteration\n        train_loss += loss.item()  # Accumulate the training loss\n\n    # Validation phase\n    model.eval()  # Set model to evaluation mode\n    val_loss = 0  # Initialize cumulative validation loss for the epoch\n    with torch.no_grad():  # Disable gradient calculation for validation\n        # Loop over validation data with tqdm progress bar\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n            with autocast():  # Use AMP for mixed-precision calculations\n                outputs = model(images)  # Forward pass\n                loss = criterion(outputs, labels)  # Compute loss\n            val_loss += loss.item()  # Accumulate the validation loss\n\n    # Calculate average losses and append to lists\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    progress = ((epoch + 1) / num_epochs) * 100\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f} - Progress: {progress:.2f}%\")\n\n    # Early stopping check\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss Curve for Custom CNN","metadata":{}},{"cell_type":"code","source":"# Plotting loss curves\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a path for saving the model\nmodel_save_path = \"custom_cnn_model.pth\"  # You can specify a different path or filename\n\n# Save the model after training completes or early stopping is triggered\ntorch.save(model.state_dict(), model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation and Metrics Calculation for Custom CNN","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Move model to evaluation mode\nmodel.eval()\n\n# Initialize lists to store predictions and true labels\nall_preds = []\nall_labels = []\n\n# Run inference\nwith torch.no_grad():  # Disable gradient calculation for faster inference\n    for images, labels in test_loader:\n        # Move images and labels to the same device as the model (GPU)\n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        # Forward pass\n        outputs = model(images)\n\n        # Get predictions (choose the class with the highest logit score)\n        _, predicted = torch.max(outputs, 1)\n\n        # Append predictions and true labels to lists\n        all_preds.extend(predicted.cpu().numpy())  # Move to CPU and convert to numpy\n        all_labels.extend(labels.cpu().numpy())    # Move to CPU and convert to numpy\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Transfer Learning Model\nUsing pretrained models from PyTorch.","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport timm\n\ndef get_transfer_model(model_name, num_classes):\n    if model_name == 'resnext101_32x8d':\n        model = timm.create_model('resnext101_32x8d', pretrained=True)\n        model.fc = nn.Linear(model.get_classifier().in_features, num_classes)\n\n    elif model_name == 'densenet201':\n        model = timm.create_model('densenet201', pretrained=True)\n        model.classifier = nn.Linear(model.get_classifier().in_features, num_classes)\n\n    elif model_name == 'efficientnetv2_m':\n        model = timm.create_model('efficientnetv2_m', pretrained=True)\n        model.classifier = nn.Linear(model.get_classifier().in_features, num_classes)\n\n    elif model_name == 'mobilenet_v2':\n        model = timm.create_model('mobilenet_v2', pretrained=True)\n        model.last_linear = nn.Linear(model.get_classifier().in_features, num_classes)\n\n    elif model_name == 'seresnext101_32x8d':\n        model = timm.create_model('seresnext101_32x8d', pretrained=True)\n        model.fc = nn.Linear(model.get_classifier().in_features, num_classes)\n\n    else:\n        raise ValueError(f\"Model '{model_name}' not supported. Please check the name.\")\n\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transfer Learning Example using ResNeXt101","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm  # Import tqdm for progress bars\nfrom torch.cuda.amp import autocast, GradScaler  # Import AMP utilities\n\n# Set number of epochs and initialize variables\nnum_epochs = 50  # Define the number of training epochs\nnum_classes=21\n\n# Use your custom CNN model (model_1) here\nmodel_1 = get_transfer_model('resnext101_32x8d', num_classes).to('cuda')  # Using 'model_1' for custom CNN\n\ncriterion = nn.CrossEntropyLoss()  # Loss function\n\noptimizer = optim.Adam(model_1.parameters(), lr=0.001)  # Optimizer with learning rate\n\nearly_stopping = EarlyStopping(patience=5)  # Initialize early stopping with patience\n\ntrain_losses, val_losses = [], []  # Lists to store training and validation losses per epoch\n\n# Initialize GradScaler for AMP\nscaler = GradScaler()\n\n# Loop over epochs\nfor epoch in range(num_epochs):\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    # Training phase\n    model_1.train()  # Set model to training mode\n    train_loss = 0  # Initialize cumulative training loss for the epoch\n    # Loop over training data with tqdm progress bar\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n\n        optimizer.zero_grad()  # Clear previous gradients\n\n        with autocast():  # Use AMP for mixed-precision calculations\n            outputs = model_1(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n\n        # Scale loss to avoid underflow for float16\n        scaler.scale(loss).backward()  # Backward pass with scaled loss\n        scaler.step(optimizer)  # Optimizer step\n        scaler.update()  # Update the scaler for next iteration\n        train_loss += loss.item()  # Accumulate the training loss\n\n    # Validation phase\n    model_1.eval()  # Set model to evaluation mode\n    val_loss = 0  # Initialize cumulative validation loss for the epoch\n    with torch.no_grad():  # Disable gradient calculation for validation\n        # Loop over validation data with tqdm progress bar\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n            with autocast():  # Use AMP for mixed-precision calculations\n                outputs = model_1(images)  # Forward pass\n                loss = criterion(outputs, labels)  # Compute loss\n            val_loss += loss.item()  # Accumulate the validation loss\n\n    # Calculate average losses and append to lists\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n    # Early stopping check\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n# Save the model\ntorch.save(model_1.state_dict(), 'custom_cnn_model_1.pth')  # Save the custom CNN model as 'custom_cnn_model_1.pth'\nprint(\"Model saved as 'custom_cnn_model_1.pth'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss Curve for ResNeXt101","metadata":{}},{"cell_type":"code","source":"# Plotting loss curves\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for ResNeXt101\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation and Metrics Calculation for ResNeXt101","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Move model_1 to evaluation mode\nmodel_1.eval()\n\n# Initialize lists to store predictions and true labels\nall_preds = []\nall_labels = []\n\n# Run inference\nwith torch.no_grad():  # Disable gradient calculation for faster inference\n    for images, labels in test_loader:\n        # Move images and labels to the same device as the model (GPU)\n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        # Forward pass\n        outputs = model_1(images)  # Using model_1 for prediction\n\n        # Get predictions (choose the class with the highest logit score)\n        _, predicted = torch.max(outputs, 1)\n\n        # Append predictions and true labels to lists\n        all_preds.extend(predicted.cpu().numpy())  # Move to CPU and convert to numpy\n        all_labels.extend(labels.cpu().numpy())    # Move to CPU and convert to numpy\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transfer Learning Example using densenet201","metadata":{}},{"cell_type":"code","source":"# Set number of epochs and initialize variables\nnum_epochs = 50  # Define the number of training epochs\nnum_classes=21\n\n# Initialize the DenseNet201 transfer learning model\nmodel_2 = get_transfer_model('densenet201', num_classes).to('cuda')  # Using 'model_2' for DenseNet201\n\ncriterion = nn.CrossEntropyLoss()  # Loss function\n\noptimizer = optim.Adam(model_2.parameters(), lr=0.001)  # Optimizer with learning rate\n\nearly_stopping = EarlyStopping(patience=5)  # Initialize early stopping with patience\n\ntrain_losses, val_losses = [], []  # Lists to store training and validation losses per epoch\n\n# Initialize GradScaler for AMP\nscaler = GradScaler()\n\n# Loop over epochs\nfor epoch in range(num_epochs):\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    # Training phase\n    model_2.train()  # Set model to training mode\n    train_loss = 0  # Initialize cumulative training loss for the epoch\n    \n    # Loop over training data with tqdm progress bar\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n\n        optimizer.zero_grad()  # Clear previous gradients\n\n        with autocast():  # Use AMP for mixed-precision calculations\n            outputs = model_2(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n\n        # Scale loss to avoid underflow for float16\n        scaler.scale(loss).backward()  # Backward pass with scaled loss\n        scaler.step(optimizer)  # Optimizer step\n        scaler.update()  # Update the scaler for next iteration\n        train_loss += loss.item()  # Accumulate the training loss\n\n    # Validation phase\n    model_2.eval()  # Set model to evaluation mode\n    val_loss = 0  # Initialize cumulative validation loss for the epoch\n    with torch.no_grad():  # Disable gradient calculation for validation\n        # Loop over validation data with tqdm progress bar\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n            with autocast():  # Use AMP for mixed-precision calculations\n                outputs = model_2(images)  # Forward pass\n                loss = criterion(outputs, labels)  # Compute loss\n            val_loss += loss.item()  # Accumulate the validation loss\n\n    # Calculate average losses and append to lists\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n    # Early stopping check\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n# Save the model\ntorch.save(model_2.state_dict(), 'densenet201_model_2.pth')  # Save the DenseNet201 model as 'densenet201_model_2.pth'\nprint(\"Model saved as 'densenet201_model_2.pth'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss Curve for densenet201","metadata":{}},{"cell_type":"code","source":"# Plotting loss curves\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for densenet201\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation and Metrics Calculation for densenet201","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Move model_2 to evaluation mode\nmodel_2.eval()\n\n# Initialize lists to store predictions and true labels\nall_preds = []\nall_labels = []\n\n# Run inference\nwith torch.no_grad():  # Disable gradient calculation for faster inference\n    for images, labels in test_loader:\n        # Move images and labels to the same device as the model (GPU)\n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        # Forward pass\n        outputs = model_2(images)  # Using model_2 for prediction\n\n        # Get predictions (choose the class with the highest logit score)\n        _, predicted = torch.max(outputs, 1)\n\n        # Append predictions and true labels to lists\n        all_preds.extend(predicted.cpu().numpy())  # Move to CPU and convert to numpy\n        all_labels.extend(labels.cpu().numpy())    # Move to CPU and convert to numpy\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transfer Learning Example using efficientnetv2_m","metadata":{}},{"cell_type":"code","source":"num_epochs = 50\nnum_classes=21\nmodel_3 = get_transfer_model('efficientnetv2_m', num_classes).to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_3.parameters(), lr=0.001)\nearly_stopping = EarlyStopping(patience=5)\nscaler = GradScaler()\ntrain_losses, val_losses = [], []\n\n# Loop over epochs\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    \n    # Training phase\n    model_3.train()\n    train_loss = 0\n    \n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        optimizer.zero_grad()\n\n        with autocast():\n            outputs = model_3(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        train_loss += loss.item()\n\n    # Validation phase\n    model_3.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')\n            with autocast():\n                outputs = model_3(images)\n                loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n    # Calculate average losses and append to lists\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n    # Early stopping check\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n# Save the model\ntorch.save(model_3.state_dict(), 'efficientnetv2_m_model_3.pth')\nprint(\"Model saved as 'efficientnetv2_m_model_3.pth'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss Curve for efficientnetv2_m","metadata":{}},{"cell_type":"code","source":"# Plotting loss curves\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for efficientnetv2_m\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation and Metrics Calculation for efficientnetv2_m","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Move model_3 to evaluation mode\nmodel_3.eval()\n\n# Initialize lists to store predictions and true labels\nall_preds = []\nall_labels = []\n\n# Run inference\nwith torch.no_grad():  # Disable gradient calculation for faster inference\n    for images, labels in test_loader:\n        # Move images and labels to the same device as the model (GPU)\n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        # Forward pass\n        outputs = model_3(images)  # Using model_3 for prediction\n\n        # Get predictions (choose the class with the highest logit score)\n        _, predicted = torch.max(outputs, 1)\n\n        # Append predictions and true labels to lists\n        all_preds.extend(predicted.cpu().numpy())  # Move to CPU and convert to numpy\n        all_labels.extend(labels.cpu().numpy())    # Move to CPU and convert to numpy\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transfer Learning Example using mobilenet_v2","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm  # Import tqdm for progress bars\nfrom torch.cuda.amp import autocast, GradScaler  # Import AMP utilities\n\n# Set number of epochs and initialize variables\nnum_epochs = 50  # Define the number of training epochs\nnum_classes=21\n\n# Use 'mobilenet_v2' as the base model for model_4\nmodel_4 = get_transfer_model('mobilenet_v2', num_classes).to('cuda')  # Using 'model_4' for mobilenet_v2\n\ncriterion = nn.CrossEntropyLoss()  # Loss function\n\noptimizer = optim.Adam(model_4.parameters(), lr=0.001)  # Optimizer with learning rate\n\nearly_stopping = EarlyStopping(patience=5)  # Initialize early stopping with patience\n\ntrain_losses, val_losses = [], []  # Lists to store training and validation losses per epoch\n\n# Initialize GradScaler for AMP\nscaler = GradScaler()\n\n# Loop over epochs\nfor epoch in range(num_epochs):\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    # Training phase\n    model_4.train()  # Set model to training mode\n    train_loss = 0  # Initialize cumulative training loss for the epoch\n    # Loop over training data with tqdm progress bar\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n\n        optimizer.zero_grad()  # Clear previous gradients\n\n        with autocast():  # Use AMP for mixed-precision calculations\n            outputs = model_4(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n\n        # Scale loss to avoid underflow for float16\n        scaler.scale(loss).backward()  # Backward pass with scaled loss\n        scaler.step(optimizer)  # Optimizer step\n        scaler.update()  # Update the scaler for next iteration\n        train_loss += loss.item()  # Accumulate the training loss\n\n    # Validation phase\n    model_4.eval()  # Set model to evaluation mode\n    val_loss = 0  # Initialize cumulative validation loss for the epoch\n    with torch.no_grad():  # Disable gradient calculation for validation\n        # Loop over validation data with tqdm progress bar\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n            with autocast():  # Use AMP for mixed-precision calculations\n                outputs = model_4(images)  # Forward pass\n                loss = criterion(outputs, labels)  # Compute loss\n            val_loss += loss.item()  # Accumulate the validation loss\n\n    # Calculate average losses and append to lists\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n    # Early stopping check\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n# Save the model\ntorch.save(model_4.state_dict(), 'mobilenet_v2_model_4.pth')  # Save the mobilenet_v2 model as 'nasnetalarge_model.pth'\nprint(\"Model saved as 'mobilenet_v2_model_4.pth'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss Curve for mobilenet_v2","metadata":{}},{"cell_type":"code","source":"# Plotting loss curves\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for mobilenet_v2\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation and Metrics Calculation for mobilenet_v2","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Move model_4 to evaluation mode\nmodel_4.eval()\n\n# Initialize lists to store predictions and true labels\nall_preds = []\nall_labels = []\n\n# Run inference\nwith torch.no_grad():  # Disable gradient calculation for faster inference\n    for images, labels in test_loader:\n        # Move images and labels to the same device as the model (GPU)\n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        # Forward pass\n        outputs = model_4(images)  # Using model_4 for prediction\n\n        # Get predictions (choose the class with the highest logit score)\n        _, predicted = torch.max(outputs, 1)\n\n        # Append predictions and true labels to lists\n        all_preds.extend(predicted.cpu().numpy())  # Move to CPU and convert to numpy\n        all_labels.extend(labels.cpu().numpy())    # Move to CPU and convert to numpy\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transfer Learning Example using seresnext101_32x8d","metadata":{}},{"cell_type":"code","source":"# Set number of epochs and initialize variables\nnum_epochs = 50  # Define the number of training epochs\nnum_classes=21\n\n# Use 'seresnext101_32x8d' as the base model for model_6\nmodel_5 = get_transfer_model('seresnext101_32x8d', num_classes).to('cuda')  # Using 'model_6' for SEResNext101-32x8d\n\ncriterion = nn.CrossEntropyLoss()  # Loss function\n\noptimizer = optim.Adam(model_5.parameters(), lr=0.001)  # Optimizer with learning rate\n\nearly_stopping = EarlyStopping(patience=5)  # Initialize early stopping with patience\n\ntrain_losses, val_losses = [], []  # Lists to store training and validation losses per epoch\n\n# Initialize GradScaler for AMP\nscaler = GradScaler()\n\n# Loop over epochs\nfor epoch in range(num_epochs):\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    # Training phase\n    model_5.train()  # Set model to training mode\n    train_loss = 0  # Initialize cumulative training loss for the epoch\n    # Loop over training data with tqdm progress bar\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n\n        optimizer.zero_grad()  # Clear previous gradients\n\n        with autocast():  # Use AMP for mixed-precision calculations\n            outputs = model_5(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n\n        # Scale loss to avoid underflow for float16\n        scaler.scale(loss).backward()  # Backward pass with scaled loss\n        scaler.step(optimizer)  # Optimizer step\n        scaler.update()  # Update the scaler for next iteration\n        train_loss += loss.item()  # Accumulate the training loss\n\n    # Validation phase\n    model_5.eval()  # Set model to evaluation mode\n    val_loss = 0  # Initialize cumulative validation loss for the epoch\n    with torch.no_grad():  # Disable gradient calculation for validation\n        # Loop over validation data with tqdm progress bar\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  # Move data to GPU\n            with autocast():  # Use AMP for mixed-precision calculations\n                outputs = model_5(images)  # Forward pass\n                loss = criterion(outputs, labels)  # Compute loss\n            val_loss += loss.item()  # Accumulate the validation loss\n\n    # Calculate average losses and append to lists\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n    # Early stopping check\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n# Save the model\ntorch.save(model_5.state_dict(), 'seresnext101_32x8d_model_5.pth')  # Save the SEResNext101-32x8d model as 'seresnext101_32x8d_model.pth'\nprint(\"Model saved as 'seresnext101_32x8d_model_5.pth'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss Curve for seresnext101_32x8d","metadata":{}},{"cell_type":"code","source":"# Plotting loss curves\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for seresnext101_32x8d\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation and Metrics Calculation for seresnext101_32x8d","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Move model_6 to evaluation mode\nmodel_5.eval()\n\n# Initialize lists to store predictions and true labels\nall_preds = []\nall_labels = []\n\n# Run inference\nwith torch.no_grad():  # Disable gradient calculation for faster inference\n    for images, labels in test_loader:\n        # Move images and labels to the same device as the model (GPU)\n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        # Forward pass\n        outputs = model_5(images)  # Using model_6 for prediction\n\n        # Get predictions (choose the class with the highest logit score)\n        _, predicted = torch.max(outputs, 1)\n\n        # Append predictions and true labels to lists\n        all_preds.extend(predicted.cpu().numpy())  # Move to CPU and convert to numpy\n        all_labels.extend(labels.cpu().numpy())    # Move to CPU and convert to numpy\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## XAI - Grad-CAM, Grad-CAM++, Eigen-CAM","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom torchvision import models\nfrom pytorch_grad_cam import GradCAM, GradCAMPlusPlus, EigenCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n\nclass_names = dataset.classes\n\n# Load the fine-tuned DenseNet-201 model\nnum_classes = len(dataset.classes)\nmodel = models.densenet201(weights=models.DenseNet201_Weights.IMAGENET1K_V1)\nmodel.classifier = nn.Linear(model.classifier.in_features, num_classes)\nmodel.load_state_dict(torch.load(\"densenet201_model_2.pth\"))  # ✅ Correct filename\nmodel = model.to('cuda')\nmodel.eval()\n\n# Select a sample image from the test dataset\nsample_image, _ = test_dataset[0]\nsample_image = sample_image.unsqueeze(0).to('cuda')  # Add batch dimension and move to GPU\n\n# Convert sample image to numpy for visualization\noriginal_image_np = sample_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\noriginal_image_np = (original_image_np * 0.5) + 0.5  # Unnormalize\noriginal_image_np = np.clip(original_image_np, 0, 1)\n\n# Set up Grad-CAM, Grad-CAM++, and Eigen-CAM\ntarget_layers = [model.features[-1]]  # Last conv layer of DenseNet\n\n# Initialize CAM methods\ngradcam = GradCAM(model=model, target_layers=target_layers)\ngradcam_plus_plus = GradCAMPlusPlus(model=model, target_layers=target_layers)\neigen_cam = EigenCAM(model=model, target_layers=target_layers)\n\n# Run inference to get the predicted class\nwith torch.no_grad():\n    outputs = model(sample_image)\n    predicted_class = outputs.argmax().item()\n    predicted_class_name = class_names[predicted_class]  # Get the class name\n\n# Define the target class for CAM methods\ntarget = [ClassifierOutputTarget(predicted_class)]\n\n# Generate heatmaps using Grad-CAM, Grad-CAM++, and Eigen-CAM\ngradcam_heatmap = gradcam(input_tensor=sample_image, targets=target)[0]\ngradcam_pp_heatmap = gradcam_plus_plus(input_tensor=sample_image, targets=target)[0]\neigen_cam_heatmap = eigen_cam(input_tensor=sample_image, targets=target)[0]\n\n# Overlay the heatmaps on the original image\ngradcam_result = show_cam_on_image(original_image_np, gradcam_heatmap, use_rgb=True)\ngradcam_pp_result = show_cam_on_image(original_image_np, gradcam_pp_heatmap, use_rgb=True)\neigen_cam_result = show_cam_on_image(original_image_np, eigen_cam_heatmap, use_rgb=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot the original image and CAM results\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 4, 1)\nplt.imshow(original_image_np)\nplt.title(f\"Original Image\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 4, 2)\nplt.imshow(gradcam_result)\nplt.title(f\"Grad-CAM\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 4, 3)\nplt.imshow(gradcam_pp_result)\nplt.title(f\"Grad-CAM++\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 4, 4)\nplt.imshow(eigen_cam_result)\nplt.title(f\"Eigen-CAM\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LIME","metadata":{}},{"cell_type":"code","source":"from lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom torchvision import models\nimport matplotlib.pyplot as plt\n\n# Load the fine-tuned DenseNet-201 model\nnum_classes = len(dataset.classes)\nmodel = models.densenet201(weights=models.DenseNet201_Weights.IMAGENET1K_V1)\nmodel.classifier = nn.Linear(model.classifier.in_features, num_classes)\nmodel.load_state_dict(torch.load(\"densenet201_model_2.pth\"))\nmodel = model.to('cuda')\nmodel.eval()\n\n# Select a sample image from the dataset and preprocess it for display\nsample_image, _ = dataset[0]  # Get the first image from the dataset\noriginal_image_np = sample_image.permute(1, 2, 0).cpu().numpy()\noriginal_image_np = (original_image_np * 0.5) + 0.5  # Unnormalize\noriginal_image_np = np.clip(original_image_np, 0, 1)  # Ensure valid range [0, 1]\n\n# Define a function to make predictions for LIME\ndef batch_predict(images):\n    model.eval()\n    # Convert numpy arrays to PIL images and apply transformations\n    batch = torch.stack([transform_test(Image.fromarray((image * 255).astype(np.uint8))) for image in images], dim=0).to('cuda')\n    with torch.no_grad():\n        logits = model(batch)\n    return logits.cpu().numpy()\n\n# Initialize LIME explainer\nexplainer = lime_image.LimeImageExplainer()\n\n# Generate LIME explanation for the sample image\nlime_explanation = explainer.explain_instance(\n    original_image_np,  # Original image in numpy format\n    batch_predict,      # Prediction function\n    top_labels=1,       # Focus on the top predicted class\n    hide_color=0,\n    num_samples=100     # Number of perturbed samples\n)\n\n# Get the predicted class\npredicted_class = model(sample_image.unsqueeze(0).to('cuda')).argmax().item()\n\n# Get the image and mask for the predicted class\nlime_img, lime_mask = lime_explanation.get_image_and_mask(\n    label=predicted_class,\n    positive_only=True,\n    hide_rest=False,\n    num_features=10,\n    min_weight=0.01\n)\nlime_img = mark_boundaries(lime_img, lime_mask)\n\n# Display the original and LIME result\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.imshow(original_image_np)\nplt.title(f\"Original Image\\n(Predicted: {class_names[predicted_class]})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(lime_img)\nplt.title(f\"LIME\\n(Predicted: {class_names[predicted_class]})\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}